{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "DS4400_Final_Project.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3",
      "language": "python"
    },
    "language_info": {
      "name": "python",
      "version": "3.8.3-final"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iOiRw2vCeFmM"
      },
      "source": [
        "# DS 4400 Final Project\n",
        "## Devanagari Handwritten Character Classification"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fzV9kIFQaqQ8"
      },
      "source": [
        "### Eirean Co, Levi Kaplan, Justine Luo\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oGmaDT6YelAo"
      },
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "\n",
        "\n",
        "import os\n",
        "from PIL import Image\n",
        "\n",
        "import torch\n",
        "from torch import nn\n",
        "from torch.utils.data import DataLoader\n",
        "from torchvision import datasets\n",
        "from torchvision.transforms import ToTensor, Lambda, Compose\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.svm import SVC\n",
        "from sklearn.metrics import accuracy_score\n",
        "from sklearn.metrics import classification_report\n",
        "from sklearn.metrics import accuracy_score\n",
        "from sklearn.model_selection import cross_val_score\n",
        "from sklearn.model_selection import KFold\n",
        "from sklearn.model_selection import GridSearchCV\n",
        "from sklearn.naive_bayes import GaussianNB\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "from sklearn.model_selection import StratifiedKFold"
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "\"\"\"\n",
        "    Takes the DevanagariHandwrittenCharacter dataset and turns it into a \n",
        "        Pandas DataFrame, with the values of each pixel for each image from 0 to 255 \n",
        "        as the first 2024 columns and the corresponding character name as the final column.\n",
        "\"\"\"\n",
        "feature_list = list()\n",
        "parent_directory = \"DevanagariHandwrittenCharacterDataset/\"\n",
        "# loops through directory, getting the test and train folders\n",
        "for parent_folder in os.listdir(parent_directory):\n",
        "    child_directory = os.path.join(parent_directory, parent_folder)\n",
        "    # goes through test and train folders\n",
        "    for child_folder in os.listdir(child_directory):\n",
        "        # gets the name of the character that this folder is for\n",
        "        split_str = child_folder.split(\"_\")\n",
        "        current_character = split_str[-1]\n",
        "        # goes through each image in the folder and adds it to the feature list\n",
        "        for img in os.listdir(os.path.join(child_directory, child_folder)):\n",
        "            img_directory = os.path.join(child_directory, child_folder)\n",
        "            if img.endswith(\".png\"):\n",
        "                imframe = Image.open(os.path.join(img_directory, img))\n",
        "                npframe = np.array(imframe.getdata())\n",
        "                npframe_with_char = np.append(npframe, current_character)\n",
        "                feature_list.append(npframe_with_char)\n",
        "# turn feature list into an array\n",
        "feature_array = np.asarray(feature_list)\n",
        "# create a dataframe for the array\n",
        "feature_df = pd.DataFrame(feature_array)\n",
        "# save the df as a csv\n",
        "feature_df.to_csv(\"devanagari_df.csv\")\n",
        "feature_df"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "X8K6UgTbnPs1"
      },
      "source": [
        "# Load the dataset\n",
        "df = pd.read_csv(r'devanagari_df.csv')\n",
        "df = df.dropna()\n",
        "\n",
        "# define the features\n",
        "features = df.iloc[:, 1:1025]\n",
        "features = features.astype('int64')\n",
        "\n",
        "# define the target, using consistent types (as some targets are initially ints)\n",
        "target = df.iloc[:, 1025]\n",
        "target = target.astype(str)\n",
        "features"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "       0  1  2  3  4  5  6  7  8  9  ...  1014  1015  1016  1017  1018  1019  \\\n",
              "0      0  0  0  0  0  0  0  0  0  0  ...     0     0     0     0     0     0   \n",
              "1      0  0  0  0  0  0  0  0  0  0  ...     0     0     0     0     0     0   \n",
              "2      0  0  0  0  0  0  0  0  0  0  ...     0     0     0     0     0     0   \n",
              "3      0  0  0  0  0  0  0  0  0  0  ...     0     0     0     0     0     0   \n",
              "4      0  0  0  0  0  0  0  0  0  0  ...     0     0     0     0     0     0   \n",
              "...   .. .. .. .. .. .. .. .. .. ..  ...   ...   ...   ...   ...   ...   ...   \n",
              "91995  0  0  0  0  0  0  0  0  0  0  ...     0     0     0     0     0     0   \n",
              "91996  0  0  0  0  0  0  0  0  0  0  ...     0     0     0     0     0     0   \n",
              "91997  0  0  0  0  0  0  0  0  0  0  ...     0     0     0     0     0     0   \n",
              "91998  0  0  0  0  0  0  0  0  0  0  ...     0     0     0     0     0     0   \n",
              "91999  0  0  0  0  0  0  0  0  0  0  ...     0     0     0     0     0     0   \n",
              "\n",
              "       1020  1021  1022  1023  \n",
              "0         0     0     0     0  \n",
              "1         0     0     0     0  \n",
              "2         0     0     0     0  \n",
              "3         0     0     0     0  \n",
              "4         0     0     0     0  \n",
              "...     ...   ...   ...   ...  \n",
              "91995     0     0     0     0  \n",
              "91996     0     0     0     0  \n",
              "91997     0     0     0     0  \n",
              "91998     0     0     0     0  \n",
              "91999     0     0     0     0  \n",
              "\n",
              "[92000 rows x 1024 columns]"
            ],
            "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>0</th>\n      <th>1</th>\n      <th>2</th>\n      <th>3</th>\n      <th>4</th>\n      <th>5</th>\n      <th>6</th>\n      <th>7</th>\n      <th>8</th>\n      <th>9</th>\n      <th>...</th>\n      <th>1014</th>\n      <th>1015</th>\n      <th>1016</th>\n      <th>1017</th>\n      <th>1018</th>\n      <th>1019</th>\n      <th>1020</th>\n      <th>1021</th>\n      <th>1022</th>\n      <th>1023</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>...</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>...</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>...</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>...</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>...</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>91995</th>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>...</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>91996</th>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>...</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>91997</th>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>...</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>91998</th>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>...</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>91999</th>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>...</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n  </tbody>\n</table>\n<p>92000 rows × 1024 columns</p>\n</div>"
          },
          "metadata": {},
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kPD6a3x1n4eq"
      },
      "source": [
        "# get the train test split\n",
        "X_train, X_test, y_train, y_test = train_test_split(features, target, random_state=3000)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Naive Bayes"
      ],
      "metadata": {
        "id": "3JsMwFoTSMcU"
      }
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TIc_iSGbaXeC",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "146c7ea1-4ac8-4f58-fcfc-0c91f7e4fd29"
      },
      "source": [
        "# fit a gaussian Naive Bayes to the data\n",
        "gnb = GaussianNB()\n",
        "gnb.fit(X_train, y_train)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "GaussianNB()"
            ]
          },
          "metadata": {},
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "predicted_test = gnb.predict(X_test)\n",
        "predicted_train = gnb.predict(X_train)"
      ],
      "metadata": {
        "id": "2P76tsQZtOZ0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "acc_test = accuracy_score(predicted_test, y_test)\n",
        "print('test accuracy', acc_test)\n",
        "acc_train = accuracy_score(predicted_train, y_train)\n",
        "print('train accuracy', acc_train)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SiIRWDzRYsL6",
        "outputId": "708b3f6a-9c6a-440e-f523-2bff57b59c10"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "test accuracy 0.4715086646279307\n",
            "train accuracy 0.4776758409785933\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# define search\n",
        "params_NB = {'var_smoothing': np.logspace(0,-9, num=10)}\n",
        "search = GridSearchCV(gnb, params_NB, scoring='accuracy')\n",
        "search.fit(X_train, y_train)\n",
        "model = search.best_estimator_ # GaussianNB(var_smoothing=0.1)\n",
        "print(model)\n",
        "scores = cross_val_score(model, features, target, scoring='accuracy')\n",
        "# report performance\n",
        "print('Accuracy: %.3f Std: (%.3f)' % (np.mean(scores), np.std(scores)))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XqPh6ZWRY0Gp",
        "outputId": "a41bc366-71d6-4c76-b0d9-54b087ada172"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "GaussianNB(var_smoothing=0.1)\n",
            "Accuracy: 0.529 (0.001)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NtLv3Z7dakZa",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "1157d694-5bab-459b-9715-475eca0ccca5"
      },
      "source": [
        "# optimal smoothing found via grid search \n",
        "optimal_nb_model = search.best_estimator_\n",
        "opt_nb_predicted_test = optimal_nb_model.predict(X_test)\n",
        "opt_nb_predicted_train = optimal_nb_model.predict(X_train)\n",
        "print(classification_report(y_test, opt_nb_predicted_test))\n",
        "print(classification_report(y_train, opt_nb_predicted_train))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.76      0.97      0.85        76\n",
            "           1       0.31      0.88      0.46        58\n",
            "           2       0.67      0.60      0.64       518\n",
            "           3       0.70      0.45      0.55       486\n",
            "           4       0.65      0.81      0.72       494\n",
            "           5       0.72      0.78      0.75       507\n",
            "           6       0.57      0.68      0.62        91\n",
            "           7       0.37      0.78      0.51        74\n",
            "           8       0.15      0.84      0.26        77\n",
            "           9       0.21      0.66      0.31        65\n",
            "        adna       0.65      0.50      0.56       505\n",
            "          ba       0.52      0.33      0.40       498\n",
            "         bha       0.79      0.50      0.61       512\n",
            "         cha       0.57      0.67      0.62       500\n",
            "        chha       0.76      0.37      0.49       495\n",
            "       chhya       0.38      0.76      0.51       509\n",
            "          da       0.58      0.43      0.49       517\n",
            "         daa       0.79      0.29      0.42       518\n",
            "         dha       0.49      0.55      0.52       457\n",
            "        dhaa       0.73      0.58      0.65       521\n",
            "          ga       0.66      0.45      0.53       494\n",
            "         gha       0.50      0.32      0.39       510\n",
            "         gya       0.59      0.57      0.58       497\n",
            "          ha       0.50      0.39      0.44       514\n",
            "          ja       0.60      0.73      0.66       492\n",
            "         jha       0.76      0.60      0.67       481\n",
            "          ka       0.76      0.64      0.69       478\n",
            "         kha       0.50      0.29      0.37       489\n",
            "         kna       0.65      0.44      0.52       505\n",
            "          la       0.71      0.58      0.64       478\n",
            "          ma       0.52      0.32      0.40       496\n",
            "     motosaw       0.70      0.41      0.52       508\n",
            "          na       0.06      0.35      0.10        55\n",
            "          pa       0.32      0.65      0.43       500\n",
            "   patalosaw       0.52      0.27      0.36       489\n",
            "petchiryakha       0.39      0.61      0.48       527\n",
            "         pha       0.59      0.67      0.63       497\n",
            "          ra       0.42      0.72      0.53       503\n",
            "    taamatar       0.73      0.81      0.77       479\n",
            "      tabala       0.53      0.62      0.57       540\n",
            "         tha       0.58      0.28      0.38       506\n",
            "        thaa       0.69      0.64      0.66       484\n",
            "         tra       0.33      0.55      0.41       520\n",
            "         waw       0.50      0.39      0.44       527\n",
            "         yaw       0.05      0.12      0.08        75\n",
            "         yna       0.63      0.65      0.64       498\n",
            "\n",
            "    accuracy                           0.54     19620\n",
            "   macro avg       0.55      0.55      0.52     19620\n",
            "weighted avg       0.59      0.54      0.54     19620\n",
            "\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.70      0.96      0.81       224\n",
            "           1       0.36      0.87      0.51       242\n",
            "           2       0.68      0.66      0.67      1482\n",
            "           3       0.72      0.49      0.58      1514\n",
            "           4       0.66      0.78      0.72      1506\n",
            "           5       0.76      0.77      0.76      1493\n",
            "           6       0.66      0.76      0.71       289\n",
            "           7       0.33      0.72      0.46       226\n",
            "           8       0.15      0.86      0.26       223\n",
            "           9       0.24      0.68      0.35       235\n",
            "        adna       0.67      0.48      0.56      1495\n",
            "          ba       0.52      0.32      0.40      1502\n",
            "         bha       0.79      0.45      0.57      1488\n",
            "         cha       0.57      0.66      0.61      1500\n",
            "        chha       0.74      0.38      0.50      1505\n",
            "       chhya       0.38      0.78      0.52      1491\n",
            "          da       0.56      0.47      0.51      1483\n",
            "         daa       0.75      0.27      0.40      1482\n",
            "         dha       0.55      0.56      0.55      1543\n",
            "        dhaa       0.71      0.56      0.63      1479\n",
            "          ga       0.71      0.48      0.57      1506\n",
            "         gha       0.52      0.33      0.40      1490\n",
            "         gya       0.60      0.57      0.59      1503\n",
            "          ha       0.50      0.42      0.45      1486\n",
            "          ja       0.59      0.68      0.63      1508\n",
            "         jha       0.80      0.62      0.70      1519\n",
            "          ka       0.78      0.62      0.69      1522\n",
            "         kha       0.52      0.29      0.37      1511\n",
            "         kna       0.62      0.45      0.52      1495\n",
            "          la       0.71      0.56      0.63      1522\n",
            "          ma       0.53      0.34      0.42      1504\n",
            "     motosaw       0.70      0.42      0.52      1492\n",
            "          na       0.08      0.35      0.13       245\n",
            "          pa       0.32      0.63      0.43      1500\n",
            "   patalosaw       0.51      0.28      0.36      1511\n",
            "petchiryakha       0.38      0.64      0.48      1473\n",
            "         pha       0.59      0.67      0.63      1503\n",
            "          ra       0.41      0.70      0.52      1497\n",
            "    taamatar       0.72      0.77      0.74      1521\n",
            "      tabala       0.48      0.63      0.55      1460\n",
            "         tha       0.66      0.28      0.40      1494\n",
            "        thaa       0.71      0.67      0.69      1516\n",
            "         tra       0.31      0.54      0.40      1480\n",
            "         waw       0.47      0.34      0.40      1473\n",
            "         yaw       0.08      0.15      0.11       225\n",
            "         yna       0.65      0.68      0.66      1502\n",
            "\n",
            "    accuracy                           0.54     58860\n",
            "   macro avg       0.55      0.56      0.52     58860\n",
            "weighted avg       0.59      0.54      0.54     58860\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print('accuracy score on test with opt model', accuracy_score(opt_nb_predicted_test, y_test))\n",
        "print('accuracy score on train with opt model', accuracy_score(opt_nb_predicted_train, y_train))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xciYcG3GL5LP",
        "outputId": "3f3cf406-09c6-44f4-98fc-20577cfc5c77"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "accuracy score on test with opt model 0.5352191641182467\n",
            "accuracy score on train with opt model 0.5377505946313286\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### SVM"
      ],
      "metadata": {
        "id": "ktTXgb7lBR-p"
      }
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "a5IDwHGwngWI",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "3e3a8785-185b-46b5-a6f4-b9fcfe97d9ea"
      },
      "source": [
        "def svc_train_test_report(model, X_train, y_train, X_test, y_test):\n",
        "  model = model.fit(X_train, y_train)\n",
        "  y_pred_train_svc = model.predict(X_train)\n",
        "  train_score_svc = accuracy_score(y_train, y_pred_train_svc)\n",
        "  print(\"Training accuracy: \", train_score_svc)\n",
        "  print(classification_report(y_train, y_pred_train_svc))\n",
        "\n",
        "  y_pred_test_svc = model.predict(X_test)\n",
        "  test_score_svc = accuracy_score(y_test, y_pred_test_svc)\n",
        "  print(\"Testing accuracy: \", test_score_svc)\n",
        "  print(classification_report(y_test, y_pred_test_svc))\n",
        "\n",
        "  return model\n",
        "\n",
        "\n",
        "svc = svc_train_test_report(SVC(), X_train, y_train, X_test, y_test)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training accuracy:  0.9823562891291975\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "         bha       1.00      0.98      0.99       221\n",
            "         cha       0.98      0.99      0.99       226\n",
            "        chha       1.00      1.00      1.00       219\n",
            "         gha       0.97      0.98      0.98       224\n",
            "   patalosaw       0.98      1.00      0.99       229\n",
            "         pha       0.98      0.98      0.98       178\n",
            "        thaa       0.99      0.98      0.98       228\n",
            "         waw       0.97      0.96      0.96       232\n",
            "\n",
            "    accuracy                           0.98      1757\n",
            "   macro avg       0.98      0.98      0.98      1757\n",
            "weighted avg       0.98      0.98      0.98      1757\n",
            "\n",
            "Testing accuracy:  0.9112627986348123\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "         bha       0.94      0.95      0.94        79\n",
            "         cha       0.88      0.93      0.91        74\n",
            "        chha       0.97      0.94      0.96        81\n",
            "         gha       0.85      0.89      0.87        76\n",
            "   patalosaw       0.87      0.83      0.85        71\n",
            "         pha       0.97      0.94      0.95        65\n",
            "        thaa       0.96      0.94      0.95        72\n",
            "         waw       0.85      0.85      0.85        68\n",
            "\n",
            "    accuracy                           0.91       586\n",
            "   macro avg       0.91      0.91      0.91       586\n",
            "weighted avg       0.91      0.91      0.91       586\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cLt88y_jtOGL",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "8f8ba956-e093-4d37-f4b9-3ba1eb38f324"
      },
      "source": [
        "def svc_tune(X_train, y_train):\n",
        "  hp_grid = {'kernel': ['linear', 'poly', 'rbf'], 'C': [0.1, 1, 10, 100], 'gamma': [1, 0.1, 0.01, 0.001, 0.0001]}\n",
        "  svc_grid = GridSearchCV(SVC(), hp_grid, refit=True, verbose=3)\n",
        "  svc_grid.fit(X_train,y_train)\n",
        "  return svc_grid\n",
        "\n",
        "svc_grid = svc_tune(X_train, y_train)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fitting 5 folds for each of 60 candidates, totalling 300 fits\n",
            "[CV 1/5] END .....C=0.1, gamma=1, kernel=linear;, score=0.858 total time=   0.5s\n",
            "[CV 2/5] END .....C=0.1, gamma=1, kernel=linear;, score=0.810 total time=   0.5s\n",
            "[CV 3/5] END .....C=0.1, gamma=1, kernel=linear;, score=0.858 total time=   0.5s\n",
            "[CV 4/5] END .....C=0.1, gamma=1, kernel=linear;, score=0.795 total time=   0.5s\n",
            "[CV 5/5] END .....C=0.1, gamma=1, kernel=linear;, score=0.849 total time=   0.5s\n",
            "[CV 1/5] END .......C=0.1, gamma=1, kernel=poly;, score=0.898 total time=   0.7s\n",
            "[CV 2/5] END .......C=0.1, gamma=1, kernel=poly;, score=0.852 total time=   0.7s\n",
            "[CV 3/5] END .......C=0.1, gamma=1, kernel=poly;, score=0.909 total time=   0.7s\n",
            "[CV 4/5] END .......C=0.1, gamma=1, kernel=poly;, score=0.860 total time=   0.7s\n",
            "[CV 5/5] END .......C=0.1, gamma=1, kernel=poly;, score=0.897 total time=   0.6s\n",
            "[CV 1/5] END ........C=0.1, gamma=1, kernel=rbf;, score=0.131 total time=   1.5s\n",
            "[CV 2/5] END ........C=0.1, gamma=1, kernel=rbf;, score=0.134 total time=   1.5s\n",
            "[CV 3/5] END ........C=0.1, gamma=1, kernel=rbf;, score=0.134 total time=   1.5s\n",
            "[CV 4/5] END ........C=0.1, gamma=1, kernel=rbf;, score=0.131 total time=   1.6s\n",
            "[CV 5/5] END ........C=0.1, gamma=1, kernel=rbf;, score=0.131 total time=   1.6s\n",
            "[CV 1/5] END ...C=0.1, gamma=0.1, kernel=linear;, score=0.858 total time=   0.5s\n",
            "[CV 2/5] END ...C=0.1, gamma=0.1, kernel=linear;, score=0.810 total time=   0.5s\n",
            "[CV 3/5] END ...C=0.1, gamma=0.1, kernel=linear;, score=0.858 total time=   0.5s\n",
            "[CV 4/5] END ...C=0.1, gamma=0.1, kernel=linear;, score=0.795 total time=   0.4s\n",
            "[CV 5/5] END ...C=0.1, gamma=0.1, kernel=linear;, score=0.849 total time=   0.5s\n",
            "[CV 1/5] END .....C=0.1, gamma=0.1, kernel=poly;, score=0.898 total time=   0.7s\n",
            "[CV 2/5] END .....C=0.1, gamma=0.1, kernel=poly;, score=0.852 total time=   0.7s\n",
            "[CV 3/5] END .....C=0.1, gamma=0.1, kernel=poly;, score=0.909 total time=   0.7s\n",
            "[CV 4/5] END .....C=0.1, gamma=0.1, kernel=poly;, score=0.860 total time=   0.7s\n",
            "[CV 5/5] END .....C=0.1, gamma=0.1, kernel=poly;, score=0.897 total time=   0.7s\n",
            "[CV 1/5] END ......C=0.1, gamma=0.1, kernel=rbf;, score=0.131 total time=   1.5s\n",
            "[CV 2/5] END ......C=0.1, gamma=0.1, kernel=rbf;, score=0.134 total time=   1.6s\n",
            "[CV 3/5] END ......C=0.1, gamma=0.1, kernel=rbf;, score=0.134 total time=   1.5s\n",
            "[CV 4/5] END ......C=0.1, gamma=0.1, kernel=rbf;, score=0.131 total time=   1.5s\n",
            "[CV 5/5] END ......C=0.1, gamma=0.1, kernel=rbf;, score=0.131 total time=   1.6s\n",
            "[CV 1/5] END ..C=0.1, gamma=0.01, kernel=linear;, score=0.858 total time=   0.5s\n",
            "[CV 2/5] END ..C=0.1, gamma=0.01, kernel=linear;, score=0.810 total time=   0.4s\n",
            "[CV 3/5] END ..C=0.1, gamma=0.01, kernel=linear;, score=0.858 total time=   0.5s\n",
            "[CV 4/5] END ..C=0.1, gamma=0.01, kernel=linear;, score=0.795 total time=   0.5s\n",
            "[CV 5/5] END ..C=0.1, gamma=0.01, kernel=linear;, score=0.849 total time=   0.5s\n",
            "[CV 1/5] END ....C=0.1, gamma=0.01, kernel=poly;, score=0.898 total time=   0.7s\n",
            "[CV 2/5] END ....C=0.1, gamma=0.01, kernel=poly;, score=0.852 total time=   0.7s\n",
            "[CV 3/5] END ....C=0.1, gamma=0.01, kernel=poly;, score=0.909 total time=   0.7s\n",
            "[CV 4/5] END ....C=0.1, gamma=0.01, kernel=poly;, score=0.860 total time=   0.7s\n",
            "[CV 5/5] END ....C=0.1, gamma=0.01, kernel=poly;, score=0.897 total time=   0.6s\n",
            "[CV 1/5] END .....C=0.1, gamma=0.01, kernel=rbf;, score=0.131 total time=   1.5s\n",
            "[CV 2/5] END .....C=0.1, gamma=0.01, kernel=rbf;, score=0.134 total time=   1.5s\n",
            "[CV 3/5] END .....C=0.1, gamma=0.01, kernel=rbf;, score=0.134 total time=   1.5s\n",
            "[CV 4/5] END .....C=0.1, gamma=0.01, kernel=rbf;, score=0.131 total time=   1.5s\n",
            "[CV 5/5] END .....C=0.1, gamma=0.01, kernel=rbf;, score=0.131 total time=   1.5s\n",
            "[CV 1/5] END .C=0.1, gamma=0.001, kernel=linear;, score=0.858 total time=   0.5s\n",
            "[CV 2/5] END .C=0.1, gamma=0.001, kernel=linear;, score=0.810 total time=   0.4s\n",
            "[CV 3/5] END .C=0.1, gamma=0.001, kernel=linear;, score=0.858 total time=   0.5s\n",
            "[CV 4/5] END .C=0.1, gamma=0.001, kernel=linear;, score=0.795 total time=   0.5s\n",
            "[CV 5/5] END .C=0.1, gamma=0.001, kernel=linear;, score=0.849 total time=   0.4s\n",
            "[CV 1/5] END ...C=0.1, gamma=0.001, kernel=poly;, score=0.898 total time=   0.7s\n",
            "[CV 2/5] END ...C=0.1, gamma=0.001, kernel=poly;, score=0.852 total time=   0.6s\n",
            "[CV 3/5] END ...C=0.1, gamma=0.001, kernel=poly;, score=0.909 total time=   0.7s\n",
            "[CV 4/5] END ...C=0.1, gamma=0.001, kernel=poly;, score=0.860 total time=   0.7s\n",
            "[CV 5/5] END ...C=0.1, gamma=0.001, kernel=poly;, score=0.897 total time=   0.6s\n",
            "[CV 1/5] END ....C=0.1, gamma=0.001, kernel=rbf;, score=0.131 total time=   1.5s\n",
            "[CV 2/5] END ....C=0.1, gamma=0.001, kernel=rbf;, score=0.134 total time=   1.5s\n",
            "[CV 3/5] END ....C=0.1, gamma=0.001, kernel=rbf;, score=0.134 total time=   1.5s\n",
            "[CV 4/5] END ....C=0.1, gamma=0.001, kernel=rbf;, score=0.131 total time=   1.5s\n",
            "[CV 5/5] END ....C=0.1, gamma=0.001, kernel=rbf;, score=0.131 total time=   1.5s\n",
            "[CV 1/5] END C=0.1, gamma=0.0001, kernel=linear;, score=0.858 total time=   0.5s\n",
            "[CV 2/5] END C=0.1, gamma=0.0001, kernel=linear;, score=0.810 total time=   0.5s\n",
            "[CV 3/5] END C=0.1, gamma=0.0001, kernel=linear;, score=0.858 total time=   0.5s\n",
            "[CV 4/5] END C=0.1, gamma=0.0001, kernel=linear;, score=0.795 total time=   0.5s\n",
            "[CV 5/5] END C=0.1, gamma=0.0001, kernel=linear;, score=0.849 total time=   0.5s\n",
            "[CV 1/5] END ..C=0.1, gamma=0.0001, kernel=poly;, score=0.898 total time=   0.7s\n",
            "[CV 2/5] END ..C=0.1, gamma=0.0001, kernel=poly;, score=0.852 total time=   0.6s\n",
            "[CV 3/5] END ..C=0.1, gamma=0.0001, kernel=poly;, score=0.909 total time=   0.7s\n",
            "[CV 4/5] END ..C=0.1, gamma=0.0001, kernel=poly;, score=0.860 total time=   0.6s\n",
            "[CV 5/5] END ..C=0.1, gamma=0.0001, kernel=poly;, score=0.897 total time=   0.7s\n",
            "[CV 1/5] END ...C=0.1, gamma=0.0001, kernel=rbf;, score=0.131 total time=   1.6s\n",
            "[CV 2/5] END ...C=0.1, gamma=0.0001, kernel=rbf;, score=0.134 total time=   1.5s\n",
            "[CV 3/5] END ...C=0.1, gamma=0.0001, kernel=rbf;, score=0.134 total time=   1.5s\n",
            "[CV 4/5] END ...C=0.1, gamma=0.0001, kernel=rbf;, score=0.131 total time=   2.0s\n",
            "[CV 5/5] END ...C=0.1, gamma=0.0001, kernel=rbf;, score=0.131 total time=   1.6s\n",
            "[CV 1/5] END .......C=1, gamma=1, kernel=linear;, score=0.858 total time=   0.5s\n",
            "[CV 2/5] END .......C=1, gamma=1, kernel=linear;, score=0.810 total time=   0.4s\n",
            "[CV 3/5] END .......C=1, gamma=1, kernel=linear;, score=0.858 total time=   0.5s\n",
            "[CV 4/5] END .......C=1, gamma=1, kernel=linear;, score=0.795 total time=   0.5s\n",
            "[CV 5/5] END .......C=1, gamma=1, kernel=linear;, score=0.849 total time=   0.5s\n",
            "[CV 1/5] END .........C=1, gamma=1, kernel=poly;, score=0.898 total time=   0.7s\n",
            "[CV 2/5] END .........C=1, gamma=1, kernel=poly;, score=0.852 total time=   0.6s\n",
            "[CV 3/5] END .........C=1, gamma=1, kernel=poly;, score=0.909 total time=   0.7s\n",
            "[CV 4/5] END .........C=1, gamma=1, kernel=poly;, score=0.860 total time=   0.6s\n",
            "[CV 5/5] END .........C=1, gamma=1, kernel=poly;, score=0.897 total time=   0.6s\n",
            "[CV 1/5] END ..........C=1, gamma=1, kernel=rbf;, score=0.131 total time=   1.5s\n",
            "[CV 2/5] END ..........C=1, gamma=1, kernel=rbf;, score=0.134 total time=   1.5s\n",
            "[CV 3/5] END ..........C=1, gamma=1, kernel=rbf;, score=0.134 total time=   1.5s\n",
            "[CV 4/5] END ..........C=1, gamma=1, kernel=rbf;, score=0.131 total time=   1.5s\n",
            "[CV 5/5] END ..........C=1, gamma=1, kernel=rbf;, score=0.131 total time=   1.5s\n",
            "[CV 1/5] END .....C=1, gamma=0.1, kernel=linear;, score=0.858 total time=   0.5s\n",
            "[CV 2/5] END .....C=1, gamma=0.1, kernel=linear;, score=0.810 total time=   0.4s\n",
            "[CV 3/5] END .....C=1, gamma=0.1, kernel=linear;, score=0.858 total time=   0.5s\n",
            "[CV 4/5] END .....C=1, gamma=0.1, kernel=linear;, score=0.795 total time=   0.5s\n",
            "[CV 5/5] END .....C=1, gamma=0.1, kernel=linear;, score=0.849 total time=   0.9s\n",
            "[CV 1/5] END .......C=1, gamma=0.1, kernel=poly;, score=0.898 total time=   0.7s\n",
            "[CV 2/5] END .......C=1, gamma=0.1, kernel=poly;, score=0.852 total time=   0.6s\n",
            "[CV 3/5] END .......C=1, gamma=0.1, kernel=poly;, score=0.909 total time=   0.7s\n",
            "[CV 4/5] END .......C=1, gamma=0.1, kernel=poly;, score=0.860 total time=   0.6s\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "tuned_svc = svc_grid.best_estimator_\n",
        "print(tuned_svc.get_params())"
      ],
      "metadata": {
        "id": "GOaPzvjToNUv",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "90160c81-0f9c-4aa8-94eb-c26381ee7a17"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'C': 0.1, 'break_ties': False, 'cache_size': 200, 'class_weight': None, 'coef0': 0.0, 'decision_function_shape': 'ovr', 'degree': 3, 'gamma': 1, 'kernel': 'linear', 'max_iter': -1, 'probability': False, 'random_state': None, 'shrinking': True, 'tol': 0.001, 'verbose': False}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "svc_train_test_report(tuned_svc, X_train, y_train, X_test, y_test)"
      ],
      "metadata": {
        "id": "msyv5SD5Z-Mw",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "bceed7e7-04da-43d9-c0b9-0d4bcc979cd2"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training accuracy:  1.0\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "         cha       1.00      1.00      1.00        66\n",
            "         waw       1.00      1.00      1.00       229\n",
            "\n",
            "    accuracy                           1.00       295\n",
            "   macro avg       1.00      1.00      1.00       295\n",
            "weighted avg       1.00      1.00      1.00       295\n",
            "\n",
            "Testing accuracy:  0.9090909090909091\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "         cha       0.91      0.75      0.82        28\n",
            "         waw       0.91      0.97      0.94        71\n",
            "\n",
            "    accuracy                           0.91        99\n",
            "   macro avg       0.91      0.86      0.88        99\n",
            "weighted avg       0.91      0.91      0.91        99\n",
            "\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "SVC(C=0.1, gamma=1, kernel='linear')"
            ]
          },
          "metadata": {},
          "execution_count": 25
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Neural Networks"
      ],
      "metadata": {
        "id": "6qhzjDD1kLFl"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# import the csv as a pandas dataframe \n",
        "df = pd.read_csv(\"devanagari_df.csv\", index_col=0)\n",
        "df"
      ],
      "metadata": {
        "id": "4OdBCpf1kJjV",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "9ac6ad99-db8b-41cb-9545-946c459e7d07"
      },
      "execution_count": 44,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/IPython/core/interactiveshell.py:2718: DtypeWarning: Columns (1025) have mixed types.Specify dtype option on import or set low_memory=False.\n",
            "  interactivity=interactivity, compiler=compiler, result=result)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\"\"\"\n",
        "    Defines the Feed Forward Neural Network Module.\n",
        "    This module takes in the number of hidden layers, the nodes per layer, the training data, and the activation function,\n",
        "        and outputs the model to be trained using its forward method.\n",
        "    Args:\n",
        "        num_hidden_layers (Int): the number of hidden layers of the neural network (doesn't include the input/output layers)\n",
        "        nodes_per_layer (List[Int]): the number of nodes per layer. The last one should be 1, and the length should be (2 + num_hidden_layers)\n",
        "        activation_function (Function): Must be one of torch.nn.Sigmoid(), torch.nn.ReLU(), torch.tanh(), torch.nn.Identity()\n",
        "    Returns:\n",
        "        The Feed Forward Neural Network model to be trained\n",
        "\"\"\"\n",
        "class Feed_Forward(torch.nn.Module):\n",
        "    def __init__(self, num_hidden_layers, nodes_per_layer, activation_function):\n",
        "        super(Feed_Forward, self).__init__()\n",
        "        # assert Module inputs adhere to constraints\n",
        "        assert(num_hidden_layers == len(nodes_per_layer) - 2)\n",
        "\n",
        "        self.num_hidden_layers = num_hidden_layers\n",
        "        self.nodes_per_layer = nodes_per_layer\n",
        "        self.activation_function = activation_function\n",
        "        self.layers = []\n",
        "        # define the first layer as going from the initial data count to the first hidden layer's node count\n",
        "        self.fc1 = torch.nn.Linear(nodes_per_layer[0], nodes_per_layer[1])\n",
        "        # Append the first layer and activation function to this Module\n",
        "        self.layers.append(self.fc1)\n",
        "        self.layers.append(activation_function)\n",
        "\n",
        "        # Append layers to the model for each hidden layer\n",
        "        for i in range(num_hidden_layers - 1):\n",
        "            self.layers.append(torch.nn.Linear(self.nodes_per_layer[i + 1], self.nodes_per_layer[i + 2]))\n",
        "            self.layers.append(activation_function)\n",
        "\n",
        "        # Append the output layer to the model\n",
        "        self.output_layer = torch.nn.Linear(self.nodes_per_layer[-2], self.nodes_per_layer[-1])\n",
        "        self.output_activation_sigmoid = torch.nn.Sigmoid()\n",
        "        self.layers.append(self.output_layer)\n",
        "        self.layers.append(self.output_activation_sigmoid)\n",
        "\n",
        "    # runs a step through the model, generating the output from this epoch of training\n",
        "    def forward(self, x):\n",
        "        model = torch.nn.Sequential(*self.layers)\n",
        "        return model.forward(x)"
      ],
      "metadata": {
        "id": "4v1tDZjKkJtW"
      },
      "execution_count": 46,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def train_model(model, epochs, X_trn, Y_trn):\n",
        "    \"\"\"\n",
        "        Trains the given model, performing the given number of epochs over the given Training and Testing data.\n",
        "        Args:\n",
        "            model (torch.nn.Module): The Feed Forward Neural Network to be trained\n",
        "            epochs (int): The total number of epochs to train over\n",
        "            X_trn (Tensor): the training features\n",
        "            Y_trn (Tensor): the training target\n",
        "    \"\"\"\n",
        "    # define a loss criteria for the model (use Cross-Entropy Loss, as this is a classification problem)\n",
        "    criterion = torch.nn.CrossEntropyLoss()\n",
        "    # define an optimizer for the model (use Stochastic Gradient Descent)\n",
        "    optimizer = torch.optim.Adam(model.parameters(), lr = 0.01)\n",
        "    # set the model to train\n",
        "    model.train()\n",
        "    # set default value for final layer output\n",
        "    final_layer_output = 0\n",
        "    # for every epoch, train the model\n",
        "    for epoch in range(epochs):\n",
        "        optimizer.zero_grad()\n",
        "        # Move forward through the model\n",
        "        y_pred = model(X_trn)\n",
        "        #y_pred = y_pred.type(torch.LongTensor)\n",
        "\n",
        "        # if this is the last epoch, we save the predictions\n",
        "        if(epoch == epochs - 1):\n",
        "            final_layer_output = y_pred.round()\n",
        "        # Compute the loss\n",
        "        loss = criterion(y_pred, Y_train)\n",
        "        # Back-propagate to adjust weights\n",
        "        loss.backward()\n",
        "        # Step through model\n",
        "        optimizer.step()\n",
        "    return model, final_layer_output\n"
      ],
      "metadata": {
        "id": "XBMJX5UIkJwX"
      },
      "execution_count": 47,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def create_and_train_ff_nn(num_hidden_layers, nodes_per_layer, X_trn, Y_trn, activation_function, epochs):\n",
        "    \"\"\"\n",
        "        Creates a Feed Forward Neural Network, and then trains it over the specified number of epochs\n",
        "        Args:\n",
        "            num_hidden_layers (Int): the total number of hidden layers for the neural network, either 1 or 2\n",
        "            nodes_per_layer (List[Int]): the number of nodes for each layer of the neural network\n",
        "            X_trn, Y_trn (Tensor): the training data \n",
        "            activation_function (Function): the activation function used\n",
        "            epochs (Int): the number of epochs to train over\n",
        "        Returns:\n",
        "            the trained model\n",
        "\n",
        "    \"\"\"\n",
        "    # define the feed forward model\n",
        "    model = Feed_Forward(num_hidden_layers, nodes_per_layer, activation_function)\n",
        "    # train the model and get the final output\n",
        "    model, final_layer_output = train_model(model, epochs, X_trn, Y_trn)\n",
        "    return model"
      ],
      "metadata": {
        "id": "TLeJjtY1kJ2Z"
      },
      "execution_count": 48,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def test_model(model, X_trn, Y_trn, X_tst, Y_tst):\n",
        "    # testing, so don't want to use a gradient\n",
        "    with torch.no_grad():\n",
        "        # testing the model\n",
        "        model.eval()\n",
        "        # make the predictions\n",
        "        y_pred = model(X_trn)\n",
        "        y_pred = torch.argmax(y_pred, dim=-1).cpu().detach().numpy()\n",
        "        # find the accuracy for training and testing\n",
        "        training_accuracy = accuracy_score(Y_trn, y_pred)\n",
        "        y_pred = model(X_tst)\n",
        "        y_pred = torch.argmax(y_pred, dim=-1).cpu().detach().numpy()\n",
        "        testing_accuracy = accuracy_score(Y_tst, y_pred)\n",
        "        return training_accuracy, testing_accuracy"
      ],
      "metadata": {
        "id": "yS_vWIogkUxh"
      },
      "execution_count": 49,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "features = df.iloc[:, :-1]\n",
        "target = df.iloc[:, -1]\n",
        "target = [str(x) for x in target]\n",
        "label_encoder = LabelEncoder()\n",
        "target = label_encoder.fit_transform(target)"
      ],
      "metadata": {
        "id": "TIjwE8YMkU6W"
      },
      "execution_count": 50,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "nodes_per_layer_list = [[X_train.shape[1], 100, 46], [X_train.shape[1], 100, 100, 46], [X_train.shape[1], 500, 100, 46], [X_train.shape[1], 100, 100, 100, 46], [X_train.shape[1], 100, 100, 100, 100, 46]]\n",
        "hidden_layers_list  = [len(x) - 2 for x in nodes_per_layer_list]"
      ],
      "metadata": {
        "id": "Q1D2MIf4kZP-"
      },
      "execution_count": 51,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "epochs = 20\n",
        "n_splits = 5\n",
        "activation_functions_list = [torch.nn.ReLU(), torch.nn.Sigmoid(), torch.nn.Tanh()]\n",
        "kf = StratifiedKFold(n_splits=n_splits, random_state=4400, shuffle=True)\n",
        "for a in activation_functions_list:\n",
        "  for i, nodes_per_layer in enumerate(nodes_per_layer_list):\n",
        "      num_hidden_layers = hidden_layers_list[i]\n",
        "      training_count = 0.0\n",
        "      testing_count = 0.0\n",
        "      print(\"Running model with \", num_hidden_layers, \"hidden layers: \", nodes_per_layer)\n",
        "      for train_index, test_index in kf.split(features, target):\n",
        "          X_train, X_test = features[train_index[0]:train_index[-1]], features[test_index[0]:test_index[-1]]\n",
        "          Y_train, Y_test = target[train_index[0]:train_index[-1]], target[test_index[0]:test_index[-1]]\n",
        "          X_train = X_train.to_numpy()\n",
        "          X_test = X_test.to_numpy()\n",
        "          # turn the training and testing data into tensors\n",
        "          X_train = torch.FloatTensor(X_train)\n",
        "          Y_train = torch.LongTensor(Y_train)\n",
        "          X_test = torch.FloatTensor(X_test)\n",
        "          Y_test = torch.LongTensor(Y_test)\n",
        "\n",
        "          #for a in activation_functions_list:\n",
        "          model = create_and_train_ff_nn(num_hidden_layers, nodes_per_layer, X_train, Y_train, a, epochs)\n",
        "          curr_training_count, curr_testing_count = test_model(model, X_train, Y_train, X_test, Y_test)\n",
        "          training_count = training_count + curr_training_count\n",
        "          testing_count = testing_count + curr_testing_count\n",
        "      training_accuracy = training_count / n_splits\n",
        "      testing_accuracy = testing_count / n_splits\n",
        "      print(\"\\tAverage training accuracy: \", training_accuracy)\n",
        "      print(\"\\tAverage testing accuracy: \", testing_accuracy, \"\\n\")"
      ],
      "metadata": {
        "id": "kbEZ1DjnkZVg",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "98e5b947-5490-4843-cfd3-7fc19705ccf9"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Running model with  1 hidden layers:  [1024, 100, 46]\n",
            "\tAverage training accuracy:  0.6720943043113902\n",
            "\tAverage testing accuracy:  0.6720869427530742 \n",
            "\n",
            "Running model with  2 hidden layers:  [1024, 100, 100, 46]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "U9RcZoXmkc5Q"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}